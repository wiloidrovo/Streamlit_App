{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3f1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINES & MODELS - TELCO CUSTOMER CHURN\n",
    "# Este notebook entrena, eval√∫a y exporta tres modelos:\n",
    "# Logistic Regression, Random Forest y Decision Tree\n",
    "# Cada uno en dos versiones: All features / Top features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from app.pipelines_transf import DataFramePreparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e264cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7043, 20)\n"
     ]
    }
   ],
   "source": [
    "# LOAD CLEAN DATA\n",
    "df = pd.read_csv(\"../cleaned_dataset.csv\")\n",
    "print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c034c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Churn\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215eade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN/VAL/TEST SPLIT\n",
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)\n",
    "\n",
    "train_set, val_set, test_set = train_val_test_split(df, stratify=target)\n",
    "\n",
    "X_train, y_train = train_set.drop(columns=[target]), train_set[target]\n",
    "X_val, y_val = val_set.drop(columns=[target]), val_set[target]\n",
    "X_test, y_test = test_set.drop(columns=[target]), test_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2efceac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (4225, 19)\n",
      "Transformed shape: (4225, 45)\n"
     ]
    }
   ],
   "source": [
    "# FIT PIPELINE (PREPROCESSING)\n",
    "prep = DataFramePreparer()\n",
    "prep.fit(X_train)\n",
    "\n",
    "X_train_prep = prep.transform(X_train)\n",
    "X_val_prep = prep.transform(X_val)\n",
    "X_test_prep = prep.transform(X_test)\n",
    "\n",
    "print(\"Original shape:\", X_train.shape)\n",
    "print(\"Transformed shape:\", X_train_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb17ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features: ['tenure', 'MonthlyCharges', 'InternetService_Fiber optic', 'OnlineSecurity_No', 'OnlineSecurity_No internet service', 'OnlineBackup_No internet service', 'TechSupport_No', 'Contract_Month-to-month', 'Contract_Two year', 'PaymentMethod_Electronic check']\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION (TOP FEATURES)\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "selector.fit(X_train_prep, y_train)\n",
    "top_indices = selector.get_support(indices=True)\n",
    "top_features = X_train_prep.columns[top_indices]\n",
    "print(\"Top features:\", list(top_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccaa4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTIONS & EVALUATION\n",
    "def train_and_evaluate(model, X_tr, y_tr, X_va, y_va):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_va)\n",
    "    y_proba = model.predict_proba(X_va)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_va, y_pred),\n",
    "        \"f1\": f1_score(y_va, y_pred, pos_label=\"Yes\"),\n",
    "        \"precision\": precision_score(y_va, y_pred, pos_label=\"Yes\"),\n",
    "        \"recall\": recall_score(y_va, y_pred, pos_label=\"Yes\"),\n",
    "        \"auc\": roc_auc_score(y_va.map({\"No\":0, \"Yes\":1}), y_proba) if y_proba is not None else None\n",
    "    }\n",
    "    cm = confusion_matrix(y_va, y_pred)\n",
    "    return model, metrics, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN ALL MODELS\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=5000, random_state=42),\n",
    "    \"rf\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"dt\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=5, random_state=42),\n",
    "}\n",
    "\n",
    "export_data = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name.upper()} (ALL FEATURES)...\")\n",
    "    m_all, met_all, cm_all = train_and_evaluate(model, X_train_prep, y_train, X_val_prep, y_val)\n",
    "\n",
    "    print(f\"{name.upper()} (TOP FEATURES)...\")\n",
    "    m_top, met_top, cm_top = train_and_evaluate(model, X_train_prep[top_features], y_train, X_val_prep[top_features], y_val)\n",
    "\n",
    "    # Save bundles\n",
    "    for version, m, met, cm, feats in [\n",
    "        (\"all\", m_all, met_all, cm_all, X_train_prep.columns),\n",
    "        (\"top\", m_top, met_top, cm_top, top_features)\n",
    "    ]:\n",
    "        bundle = {\n",
    "            \"pipeline\": prep,\n",
    "            \"model\": m,\n",
    "            \"features_in_\": list(feats),\n",
    "            \"target_name\": target,\n",
    "            \"metrics_val\": met,\n",
    "            \"confusion_val\": cm.tolist(),\n",
    "            \"feature_importances\": (\n",
    "                m.feature_importances_.tolist() if hasattr(m, \"feature_importances_\") else []\n",
    "            ),\n",
    "        }\n",
    "        fname = f\"../models/{name}_{version}.pkl\"\n",
    "        joblib.dump(bundle, fname)\n",
    "        export_data.append((name, version, met))\n",
    "        print(f\"Saved: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY OF RESULTS\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": n, \"Version\": v, **m} for n, v, m in export_data\n",
    "])\n",
    "print(\"\\nSummary of validation metrics:\")\n",
    "display(results)\n",
    "\n",
    "results.to_csv(\"../models/model_metrics_summary.csv\", index=False)\n",
    "print(\"Metrics saved to models/model_metrics_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
